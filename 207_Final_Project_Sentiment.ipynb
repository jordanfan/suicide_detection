{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFCzMUYZv_RA",
        "outputId": "41b618a1-30c4-4fc5-af05-1ad807e3521b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import the libraries we'll use below.\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns  # for nicer plots\n",
        "sns.set(style=\"darkgrid\")  # default style\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import metrics\n",
        "tf.get_logger().setLevel('INFO')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.util import ngrams\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the google drive to collab\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lM0VJAXwI2D",
        "outputId": "8c576c8c-a1e4-47ec-a2bf-fb7c0a06e067"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Cleaned Data**"
      ],
      "metadata": {
        "id": "S4GScJnXJD9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Cleaned Suicide Detection 2023-07-08.pkl'\n",
        "\n",
        "df = pd.read_pickle(file_path)"
      ],
      "metadata": {
        "id": "kUUtGLzPwR4W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split Cleaned Data into Train, Validation and Test**"
      ],
      "metadata": {
        "id": "NVu61pWRQ3rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df.sample(frac=0.20, random_state=3)\n",
        "df_train = df.drop(df_test.index)\n",
        "df_val = df_train.sample(frac=0.25, random_state=3)\n",
        "df_train = df.drop(df_val.index)\n",
        "\n",
        "print(df_test.shape)\n",
        "print(df_train.shape)\n",
        "print(df_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcKZCIwyYTu0",
        "outputId": "9d1d66e9-4e24-46fb-fdaa-500aa44ec46f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(46415, 7)\n",
            "(185659, 7)\n",
            "(46414, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Engineering - VADER Sentiment**"
      ],
      "metadata": {
        "id": "d8y2AiqfJHzF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tjnNyWVg3JNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sid = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "ZhoF0ga98W3r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['text_sentiment_score'] = df_train['text_cleaned'].apply(lambda text_cleaned: sid.polarity_scores(text_cleaned))\n",
        "df_train['text_sentiment_prob'] = df_train['text_sentiment_score'].apply(lambda score_dict: score_dict['compound'])\n",
        "df_train['text_sentiment'] = df_train['text_sentiment_prob'].apply(lambda c: 'pos' if c >=0 else 'neg')"
      ],
      "metadata": {
        "id": "T3p9xycxKc3k"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val['text_sentiment_score'] = df_val['text_cleaned'].apply(lambda text_cleaned: sid.polarity_scores(text_cleaned))\n",
        "df_val['text_sentiment_prob'] = df_val['text_sentiment_score'].apply(lambda score_dict: score_dict['compound'])\n",
        "df_val['text_sentiment'] = df_val['text_sentiment_prob'].apply(lambda c: 'pos' if c >=0 else 'neg')"
      ],
      "metadata": {
        "id": "nTO8A0XiKh8-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['text_sentiment_score'] = df_test['text_cleaned'].apply(lambda text_cleaned: sid.polarity_scores(text_cleaned))\n",
        "df_test['text_sentiment_prob'] = df_test['text_sentiment_score'].apply(lambda score_dict: score_dict['compound'])\n",
        "df_test['text_sentiment'] = df_test['text_sentiment_prob'].apply(lambda c: 'pos' if c >=0 else 'neg')"
      ],
      "metadata": {
        "id": "twOUi8mZxC2n"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Engineering - Bi-Grams**"
      ],
      "metadata": {
        "id": "J1eK1chZKyTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_bigrams(text):\n",
        "    return list(ngrams(text.split(), 2))"
      ],
      "metadata": {
        "id": "RyiHn_sGWzlv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['bi_grams'] = df_train['text_cleaned'].apply(lambda text_cleaned: extract_bigrams(text_cleaned))\n",
        "df_val['bi_grams'] = df_val['text_cleaned'].apply(lambda text_cleaned: extract_bigrams(text_cleaned))\n",
        "df_test['bi_grams'] = df_test['text_cleaned'].apply(lambda text_cleaned: extract_bigrams(text_cleaned))"
      ],
      "metadata": {
        "id": "6QXhrVW_V-LY"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Baseline Model - Sentiment Binary**"
      ],
      "metadata": {
        "id": "07sOZraurdNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train_Sentiment_Baseline Accuracy:', len(df_train[(df_train[\"text_sentiment\"]==\"neg\") &\n",
        "             (df_train[\"class\"]==\"suicide\")]) / len(df_train))\n",
        "\n",
        "print('Val_Sentiment_Baseline Accuracy:', len(df_val[(df_val[\"text_sentiment\"]==\"neg\") &\n",
        "             (df_val[\"class\"]==\"suicide\")]) / len(df_val))\n",
        "\n",
        "print('Test_Sentiment_Baseline Accuracy:', len(df_test[(df_test[\"text_sentiment\"]==\"neg\") &\n",
        "             (df_test[\"class\"]==\"suicide\")]) / len(df_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzprYVV5ohUd",
        "outputId": "0b066067-bfa5-4549-8844-3cbbfbcebfa7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_Sentiment_Baseline Accuracy: 0.37181068518089616\n",
            "Val_Sentiment_Baseline Accuracy: 0.37742922394105227\n",
            "Test_Sentiment_Baseline Accuracy: 0.3682214801249596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression Model - Sentiment Feature**"
      ],
      "metadata": {
        "id": "3zKl6AHfw1SZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split X and Y"
      ],
      "metadata": {
        "id": "wcYYeBoWwyWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split X and Y\n",
        "x_train_sent = df_train['text_sentiment_prob'].values.reshape(-1,1)\n",
        "x_train_bigram = df_train['bi_grams'].values.reshape(-1,1)\n",
        "y_train = df_train['class'].values.reshape(-1,1)"
      ],
      "metadata": {
        "id": "h3T_6eFtultU"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_val_sent = df_val['text_sentiment_prob'].values.reshape(-1,1)\n",
        "x_val_bigram = df_val['bi_grams'].values.reshape(-1,1)\n",
        "y_val = df_val['class'].values.reshape(-1,1)"
      ],
      "metadata": {
        "id": "DzfOo8u9wASb"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_sent = df_test['text_sentiment_prob'].values.reshape(-1,1)\n",
        "x_test_bigram = df_test['bi_grams'].values.reshape(-1,1)\n",
        "y_test = df_val['class'].values.reshape(-1,1)"
      ],
      "metadata": {
        "id": "YiQzaxD4wpG5"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_sent.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M2xjTDU0-74",
        "outputId": "91aab1a8-f2e4-45a1-bdb4-81fcf584c3d9"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(185659, 1)\n",
            "(185659, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(x_train_sent, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = logreg.predict(x_test_sent)\n",
        "y_pred = y_pred[1:]\n",
        "probabilities = logreg.predict_proba(x_test_sent)\n",
        "\n",
        "\n",
        "\n",
        "# Evaluation Test accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"LogisticRegression Accuracy:\", accuracy)\n",
        "print(\"LogisticRegression Classification Report:\")\n",
        "print(classification_report)\n",
        "\n",
        "\n",
        "print(\"LogisticRegression Probabilities:\")\n",
        "\n",
        "print(probabilities.shape)\n",
        "print(probabilities[0][0], probabilities[0][1])\n",
        "print(probabilities[1][0], probabilities[1][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p9NQr9Wwalb",
        "outputId": "52257925-9821-449e-974d-5a607047dda5"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression Accuracy: 0.49594949799629423\n",
            "LogisticRegression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " non-suicide       0.49      0.48      0.49     23050\n",
            "     suicide       0.50      0.51      0.50     23364\n",
            "\n",
            "    accuracy                           0.50     46414\n",
            "   macro avg       0.50      0.50      0.50     46414\n",
            "weighted avg       0.50      0.50      0.50     46414\n",
            "\n",
            "LogisticRegression Probabilities:\n",
            "(46415, 2)\n",
            "0.41641630141848174 0.5835836985815183\n",
            "0.6091468906909148 0.3908531093090852\n"
          ]
        }
      ]
    }
  ]
}